# workflows.R

utils::globalVariables(c("matools_env"))

#' @title Workflow: Analyze Evoked Action Potential Data
#'
#' @description Working example of how to use the functions within this package to create an analysis pipeline.
#'
#' @param data_folder_path path of data folder containing *.ASC files
#' @param data_parameters path of csv file with project parameters
#' @param histo_bin_size integer, histogram bin size. Wrapper for create_histogram_df(),
#'   defaults to 1 ms.
#' @param histo_window_size integer, histogram window size. Wrapper for create_histogram_df(),
#'   defaults to 50 ms.
#' @param histo_one_event_per_bin boolean, wrapper for create_histogram_df() arg one_event_per_bin,
#'   defaults to FALSE.
#'
#' @details This particular workflow is used to analyze the spike jitter, probability, and rate of action potentials
#'   generated by externally stimulating synaptic inputs onto the recorded neuron.
#'
#' @return tibble of aggregated data
#'
#' @examples
#' \dontrun{
#' data_path <- paste(getwd(), "data-raw/evoked_ap", sep = "/")
#' data_folder <- paste(data_path, "data", sep = "/")
#' data_parameters <- paste(data_path, "evoked_ap_parameters.csv", sep = "/")
#'
#' data_collection <- analysis_evoked_ap(
#'   data_folder_path = data_folder,
#'   data_parameters = data_parameters
#' )
#' }
#'
#' @note This workflow has hard-coded values, yet is intended to serve as a reference point.
#'
#' @importFrom tibble tibble add_row
#' @export
#' @md
analysis_evoked_ap <- function(data_folder_path,
                               data_parameters,
                               histo_bin_size = 1,
                               histo_window_size = 50,
                               histo_one_event_per_bin = FALSE) {
  set_pkg_environment(force_new = TRUE)
  set_data_directory(data_folder_path)
  import_experiment_parameters(data_parameters)

  import_check_missing_info(
    matools_env$files_in_folder,
    matools_env$parameters
  )

  for (filename in matools_env$files_to_process) {
    message(paste("Processing File:", filename))

    data <- asc_to_tibble(
      file_path = file.path(matools_env$directory_data, paste(filename, ".ASC", sep = ""))
    )

    set_experiment_parameters(parameters = matools_env$parameters, filename = filename)

    # modify the data frame
    calculate_stimulus_times(
      stimulus_time_first = matools_env$stimulus_time_of_first,
      stimulus_count = matools_env$stimulus_count,
      stimulus_isi = matools_env$stimulus_isi
    )

    data <- add_sweep_number_to_rows(
      df = data,
      sweep_duration = matools_env$sweep_duration_sec,
      sweep_count = matools_env$sweep_total,
      time_ref = "rec_time_ms"
    )

    data <- insert_rows_for_missing_sweeps(
      df = data,
      sweep_count = matools_env$sweep_total
    )

    data <- standardize_event_time(
      df = data,
      sweep_duration = matools_env$sweep_duration_sec,
      time_ref = "rec_time_ms"
    )

    data <- add_stimulus_index(
      df = data,
      time_of_stim = matools_env$time_of_stimuli,
      isi = matools_env$stimulus_isi,
      sweep_count = matools_env$sweep_total,
      recovery_stim = matools_env$stimulus_time_of_recovery
    )

    data <- add_event_index(data)

    data <- add_event_jitter(
      df = data,
      to_rise = FALSE
    )

    user_parameters <- tibble::tibble(
      condition_start = matools_env$condition_starts,
      condition_end = matools_env$condition_ends,
      condition = matools_env$condition_names
    )
    data <- add_condition_tag(
      df = data,
      parameters = user_parameters
    )

    df_histo <-
      create_histogram_df(
        df = data,
        time_of_stim = matools_env$time_of_stimuli,
        condition_names = matools_env$condition_names,
        bin_size = histo_bin_size,
        window_size = histo_window_size,
        first_bin_on_stim = FALSE,
        one_event_per_bin = histo_one_event_per_bin
      )

    # aggregate data for plotting
    if (!exists("data_collection")) {
      data_collection <-
        tibble::tibble(
          cell_id = filename,
          experiment_id = matools_env$experiment_id,
          data_events = list(data),
          data_histogram = list(df_histo)
        )
    } else {
      data_collection <-
        tibble::add_row(
          data_collection,
          cell_id = filename,
          experiment_id = matools_env$experiment_id,
          data_events = list(data),
          data_histogram = list(df_histo)
        )
    }
  }
  return(data_collection)
}

#' @title Workflow: Analyze Evoked Post-Synaptic Potential Data
#'
#' @description Working example of how to use the functions within this package to create an analysis pipeline.
#'
#' @param data_folder_path path of data folder containing *.ASC files
#' @param data_parameters path of csv file with project parameters
#'
#' @details This particular workflow is used to analyze the amplitude, failure rate, potency, paired-pulse ratio of
#'   post-synaptic potentials recorded using a intracellular electrophysiology technique.
#'
#' @return tibble of aggregated data
#'
#' @examples
#' \dontrun{
#' data_path <- paste(getwd(), "data-raw/evoked_psp", sep = "/")
#' data_folder <- paste(data_path, "data", sep = "/")
#' data_parameters <- paste(data_path, "evoked_psp_parameters.csv", sep = "/")
#'
#' data_collection <- analysis_evoked_psp(
#'   data_folder_path = data_folder,
#'   data_parameters = data_parameters
#' )
#' }
#'
#' @note This workflow has hard-coded values, yet is intended to serve as a reference point.
#'
#' @importFrom tibble tibble add_row
#' @export
#' @md
analysis_evoked_psp <- function(data_folder_path, data_parameters) {
  set_pkg_environment(force_new = TRUE)
  set_data_directory(data_folder_path)
  import_experiment_parameters(data_parameters)

  import_check_missing_info(
    dir_filenames = matools_env$files_in_folder,
    parameters = matools_env$parameters,
    skip_prompt = TRUE
  )

  for (filename in matools_env$files_to_process) {
    message(paste("Processing File:", filename))

    data <- asc_to_tibble(
      file_path = file.path(matools_env$directory_data, paste(filename, ".ASC", sep = ""))
    )
    set_experiment_parameters(matools_env$parameters, filename)

    # modify the data frame
    calculate_stimulus_times(
      stimulus_time_first = matools_env$stimulus_time_of_first,
      stimulus_count = matools_env$stimulus_count,
      stimulus_isi = matools_env$stimulus_isi
    )

    data <- add_sweep_number_to_rows(
      df = data,
      sweep_duration = matools_env$sweep_duration_sec,
      sweep_count = matools_env$sweep_total,
      time_ref = "rec_time_ms"
    )

    data <- insert_rows_for_missing_sweeps(
      df = data,
      sweep_count = matools_env$sweep_total
    )

    data <- standardize_event_time(
      df = data,
      sweep_duration = matools_env$sweep_duration_sec,
      time_ref = "rec_time_ms"
    )

    data <- add_stimulus_index(
      df = data,
      time_of_stim = matools_env$time_of_stimuli,
      isi = matools_env$stimulus_isi,
      sweep_count = matools_env$sweep_total,
      recovery_stim = matools_env$stimulus_time_of_recovery
    )

    data <- add_event_index(data)

    user_parameters <- dplyr::tibble(
      condition_start = matools_env$condition_starts,
      condition_end = matools_env$condition_ends,
      condition = matools_env$condition_names
    )
    data <- add_condition_tag(
      df = data,
      parameters = user_parameters
    )

    data <- add_event_jitter(
      df = data,
      to_rise = FALSE
    )

    data <- add_normalized_amplitude(
      df = data,
      normalize_condition = "control",
      normalize_stimulus = 1
    )

    data <- add_ppr(
      df = data,
      column_ref = "amplitude_normalized"
    )

    # aggregate data for plotting
    if (!exists("data_collection")) {
      data_collection <-
        tibble::tibble(
          cell_id = filename,
          experiment_id = matools_env$experiment_id,
          data_events = list(data)
        )
    } else {
      data_collection <-
        tibble::add_row(
          data_collection,
          cell_id = filename,
          experiment_id = matools_env$experiment_id,
          data_events = list(data)
        )
    }
  }
  return(data_collection)
}
